import mock
import re
import pprint

INPUT1 = """
"It is not always easy to see who is related to whom -- and in which ways. The following argument pertains to this question: To begin with, Lesley is a close friend of Fernando. Moreover, being a close friend of Fernando or a schoolmate of Lowell is sufficient for being a great-grandfather of Leroy. It follows that Lesley is a great-grandfather of Leroy."
"""
INPUT2 = """
 "It is not always easy to see who is related to whom -- and in which ways. The following argument pertains to this question: Whoever is not a great-grandfather of Clyde is a stepbrother of Brian. Being an ancestor of Dana is sufficient for not being a great-grandfather of Clyde. We may conclude: Everyone who is an ancestor of Dana is a stepbrother of Brian, too."
"""
INPUT3 = """Q: "It is not always easy to grasp who is consuming which products. The following argument pertains to this question: Every infrequent user of Paul Mitchell shampoo is either a rare consumer of Nioxin shampoo or a loyal buyer of Caress soap, or both. No regular consumer of Lush soap is a rare consumer of Nioxin shampoo and, in the same time, a loyal buyer of Caress soap. It follows that whoever is an infrequent user of Paul Mitchell shampoo is not a regular consumer of Lush soap."
"""

INPUTS = [INPUT1, INPUT2, INPUT3]

# start out by extracting premises and hypotheses from the input

def extract_premises_proxy(input_str):
    m = re.search(r'this question:([^"]+)\"', input_str) 
    return list(map(lambda claim: claim.strip(), m.group(1).split('. ')[:-1]))

def extract_hypothesis_proxy(input_str):
    m = re.search(r'(It follows that\s+|We may conclude:\s+)([^"]+)\.\"', input_str) 
    return m.group(2).strip()


## for debugging/visualization
def parents(x, alignments):
    return [name for name, a in alignments.items() if x in a.text]
def roots(alignments):
    return [x for x in alignments if not parents(x, alignments)]
def children(x, alignments):
    return [name for name in alignments
            if name in alignments[x].text]

def vizall():
    to_viz = []
    for s in first_round_claims_dict:
        alignments = parse(s)        
        to_viz.append((s, alignments))
    for s, alignments in to_viz:
        print('-' * 60)
        viz(s, alignments)
    print('-' * 60)

def pprintall():
    import pprint
    to_viz = {}
    for inp in INPUTS:
        to_viz[inp] = []
        premises = extract_premises_proxy(inp)
        for i, s in enumerate(premises):
            alignments = parse_premise("pqrst"[i], s)        
            to_viz[inp].append((s, alignments))
        hyp = extract_hypothesis_proxy(inp)
        alignments = parse_query("pqrst"[len(premises)], hyp)
        to_viz[inp].append((hyp, alignments))
    for inp in INPUTS:
        print('-' * 60)
        for s, alignments in to_viz[inp]:
            print(f'Sentence: {s}')
            pprint.pprint(alignments)

def viz(sentence, alignments):
    print(sentence)
    for root in roots(alignments):
        vizalign(root, alignments, 0)

def vizalign(node, alignments, indent):
        a = alignments[node]
        print(f'{"|  " * indent}{node}[text ] = "{a.text}"')
        print(f'{"|  " * indent}{node}[logic] = "{a.logic}"')
        for child in children(node, alignments):
            vizalign(child, alignments, indent + 1)

def asp(sentence, alignments):
    print(f'% {sentence}')
    for root in roots(alignments):
        aspalign(root, alignments, 0)
    
def aspalign(node, alignments, indent):
    for child in children(node, alignments):
        aspalign(child, alignments, indent + 1)
    a = alignments[node]
    def print_logic(s):
        print(f'{"  " * indent}{s}  % {a.text}')
    if ' =def= ' in a.logic:
        lhs, rhs = a.logic.split(' =def= ')
        if rhs.endswith('.'):
            rhs = rhs[:-1]
        print_logic(f'{lhs} :- {rhs}.')
        print_logic(f'{rhs} :- {lhs}.')
    else:
        print_logic(a.logic)

###IF prompt
import collections

Alignment = collections.namedtuple('Alignment', ['text', 'logic'])
###ENDIF prompt

first_round_claims_dict = {
    'To begin with, Lesley is a close friend of Fernando': (
        'To begin with, [rule1: Lesley is a close friend of Fernando]',
        {'rule1': Alignment('Lesley is a close friend of Fernando', 'friend("Lesley", "Fernando"). %rule1'),
         }),
    'Moreover, being a close friend of Fernando or a schoolmate of Lowell is sufficient for being a great-grandfather of Leroy': (
        'Moreover, [p1(X): being a close friend of Fernando] or [p2(X): a schoolmate of Lowell] is sufficient for [p3(X): being a great-grandfather of Leroy]',
        {'p1(X)': Alignment('being a close friend of Fernando', 'p1(X) =def= friend(X, "Fernando").'),
         'p2(X)': Alignment('a schoolmate of Lowell', 'p2(X) =def= schoolmate(X, "Lowell").'),
         'p3(X)': Alignment('being a great-grandfather of Leroy', 'p3(X) =def= great_grandfather(X, "Leroy").'),
        }),
    'Lesley is a great-grandfather of Leroy': (
        '[rule1: Lesley is a great-grandfather of Leroy]',
        {'rule1': Alignment(
            'Lesley is a great-grandfather of Leroy', 
            'query_true :- great_grandfather("Lesley", "Leroy"). %query'),
         }),
    'Whoever is not a great-grandfather of Clyde is a stepbrother of Brian': (
        'Whoever is [p1(X): not a great-grandfather of Clyde] is [p2(X): a stepbrother of Brian]',
        {'p1(X)': Alignment('not a great-grandfather of Clyde', 'p1(X) =def= -great_grandfather(X, "Clyde").'),
         'p2(X)': Alignment('a stepbrother of Brian', 'p2(X) =def= stepbrother(X, "Brian")'),
         }),
    'Being an ancestor of Dana is sufficient for not being a great-grandfather of Clyde': (
        '[p1(X): Being an ancestor of Dana] is sufficient for [p2(X): not being a great-grandfather of Clyde]',
        {'p1(X)': Alignment('Being an ancestor of Dana', 'p1(X) =def= ancestor(X, "Dana").'),
         'p2(X)': Alignment('not being a great-grandfather of Clyde', 'p2(X) =def= -great_grandfather(X, "Clyde").'),
         }),
    'Everyone who is an ancestor of Dana is a stepbrother of Brian, too': (
        'Everyone who is [p1(X): an ancestor of Dana] is [p2(X): a stepbrother of Brian], too', #hyp
        {'p1(X)': Alignment('an ancestor of Dana', 'p1(X) =def= ancestor(X, "Dana").'),
         'p2(X)': Alignment('a stepbrother of Brian', 'p2(X) =def= stepbrother(X, "Brian").'),
         }),
    'Every infrequent user of Paul Mitchell shampoo is either a rare consumer of Nioxin shampoo or a loyal buyer of Caress soap, or both': (
        'Every [p1(X): infrequent user of Paul Mitchell shampoo] is either [p2(X): a rare consumer of Nioxin shampoo] or [p3(X): a loyal buyer of Caress soap], or both',
        {'p1(X)': Alignment('infrequent user of Paul Mitchell shampoo', 'p1(X) =def= infrequent_user(X, "Paul Mitchell shampoo").'),
         'p2(X)': Alignment('a rare consumer of Nioxin shampoo', 'p2(X) =def= rare_consumer(X, "Nioxin shampoo").'),
         'p3(X)': Alignment('loyal buyer of Caress soap', 'p3(X) =def= regular_consumer(X, "Caress soap").'),
         }),
    'No regular consumer of Lush soap is a rare consumer of Nioxin shampoo and, in the same time, a loyal buyer of Caress soap': (
        'No [p1(X): regular consumer of Lush soap] is [p2(X): a rare consumer of Nioxin shampoo] and, in the same time, [p3(X): a loyal buyer of Caress soap]',
        {'p1(X)': Alignment('regular consumer of Lush soap', 'p1(X) =def= regular_consumer(X, "Lush soap").'),
         'p2(X)': Alignment('a rare consumer of Nioxin shampoo', 'p2(X) =def= rare_consumer(X, "Nioxin shampoo").'),
         'p3(X)': Alignment('a loyal buyer of Caress soap', 'p3(X) =def= regular_consumer(X, "Caress soap").'),
         }),
    'whoever is an infrequent user of Paul Mitchell shampoo is not a regular consumer of Lush soap': (
        'whoever is an [p1(X): infrequent user of Paul Mitchell shampoo] is [p2(X): not a regular consumer of Lush soap]',
        {'p1(X)': Alignment('infrequent user of Paul Mitchell shampoo', 'p1(X) =def= infrequent_user(X, "Paul Mitchell shampoo").'),
         'p2(X)': Alignment('not a regular consumer of Lush soap', 'p2(X) =def= -regular_consumer(X, "Lush soap").'),
         }),
}

second_round_claims_dict = {
    'Moreover, p1(X) or p2(X) is sufficient for p3(X)': (
        'Moreover, [rule1: p1(X) or p2(X) is sufficient for p3(X)]', 
        {'rule1': Alignment('p1(X) or p2(X) is sufficient for p3(X)', 'p3(X) :- p1(X). p3(X) :- p2(X). %rule1')}
    ),
    'p1(X)': (
        '[rule1: To begin with, p1(X)]',
        {'rule1': Alignment('To begin with, p1(X)', 'p1(X). %rule1')}),
    'Whoever is p1(X) is p2(X)': (
        '[rule1: Whoever is p1(X) is p2(X)]', 
        {'rule1': Alignment('Whoever is p1(X) is p2(X)', 'p2(X) :- p1(X). %rule1')}),
    'p1(X) is sufficient for p2(X)': (
        '[rule1: p1(X) is sufficient for p2(X)]', 
        {'rule1': Alignment('p1(X) is sufficient for p2(X)', 'p2(X) :- p1(X). %rule1')}),
    # hypothesis
    'Everyone who is p1(X) is p2(X), too': (
        '[rule1: Everyone who is p1(X) is p2(X), too]',
        {'rule1': Alignment(
            'Everyone who is p1(X) is p2(X), too', 
            'p1(someone). query_true:- p2(someone). %query')}),
    'Every p1(X) is either p2(X) or p3(X), or both': (
        '[rule1: Every p1(X) is either p2(X) or p3(X), or both]',
        {'rule1': Alignment('Every p1(X) is either p2(X) or p3(X), or both', 
                            '1 {p2(X); p3(X)} :- p1(X). %rule1')}),
    'No p1(X) is p2(X) and, in the same time, p3(X)': (
        '[rule1: No p1(X) is p2(X) and, in the same time, p3(X)]',
        {'rule1': Alignment(
            'No p1(X) is p2(X) and, in the same time, p3(X)',
            '{p2(X); p3(X)} 1 :- p1(X). %rule1')}),
    # hypothesis
    'whoever is an p1(X) is p2(X)': (
        '[rule1: whoever is an p1(X) is p2(X)]', 
        {'rule1': Alignment(
            'whoever is an p1(X) is p2(X)', 
            'p1(someone). query_true :- p2(someone). %query')}),
}

# stick this data into bracket_dict and predicate_def
bracket_dict = {}
predicate_def = {}

def insert_claims_dict(d, bracket_dict, predicate_def):
    for simplified_claim, data in d.items():
        bracketed_simplified_claim, alignments = data
        bracket_dict[simplified_claim] = bracketed_simplified_claim
        for alignment in alignments.values():
            predicate_def[alignment.text] = alignment.logic

insert_claims_dict(first_round_claims_dict, bracket_dict, predicate_def)

insert_claims_dict(second_round_claims_dict, bracket_dict, predicate_def)

def check_for_missing_defs():
    errors = {}
    for x in first_round_claims_dict.keys():
        a = parse_premise('p', x)
        for key, alignment in a.items():
            if 'undefined' in alignment.logic:
                errors[key] = alignment
    return errors

def normalize_prefix(s):
    # map whatever the predicate names are to p1, p2, ...
    s = re.sub(r'[pqrstuv](\d\(X\))', r'p\1', s)
    return re.sub(r'rule\d', 'rule1', s)

def swap_p_for_prefix(prefix, s):
    # map p1, p2, .. to q1, q2, ... etc if prefix is 'q'
    # and similar for other prefixes
    s = re.sub(
        r'[pqrstuv](\d+\(\w+\))', 
        prefix + r'\1', 
        s)
    # map rule1 to ruleN where N = prefix - 'p' + 1
    rule_n = f'rule{ord(prefix) - ord("p") + 1}'
    return re.sub('rule1', rule_n, s)

def new_preds(bracketed_text):
    preds = re.findall('\[(\w+\(\w+\))\:', bracketed_text)
    rules = re.findall('\[(rule\d+)\:', bracketed_text)
    return preds + rules

def bracket_proxy(predicate_prefix, sentence, alignment):
    # map whatever the predicate names are to p1, p2, ...
    sentence = normalize_prefix(sentence)
    if sentence in bracket_dict:
        bracketed_sentence = bracket_dict[sentence] 
        # map p1, p2, .. to q1, ... if predicate_prefix is 'q'
        bracketed_sentence = swap_p_for_prefix(
            predicate_prefix, bracketed_sentence)
        return bracketed_sentence, new_preds(bracketed_sentence)
    else:
        return None, {}

def define_predicates_proxy(predicate_prefix, bracketed_sentence, new_preds):
    result = {}
    for p in new_preds:
        text_p = bracketed_sentence.split(f'{p}:')[1].split(']')[0].lstrip()
        logic_p = predicate_def[normalize_prefix(text_p)]
        logic_p = swap_p_for_prefix(predicate_prefix, logic_p)
        result[p] = Alignment(text_p, logic_p)
    return result

def simplify_proxy(bracketed_sentence, added_alignment_keys):
    for p in added_alignment_keys:
        start = bracketed_sentence.find(f'[{p}:')
        end = bracketed_sentence[start:].find(']')
        bracketed_sentence = bracketed_sentence[:start] + p + bracketed_sentence[start + end + 1:]
    return bracketed_sentence

def parse_premise_proxy(predicate_prefix, sentence):
    return parse_proxy(predicate_prefix, False, sentence)

def parse_query_proxy(predicate_prefix, sentence):
    return parse_proxy(predicate_prefix, True, sentence)

def parse_proxy(predicate_prefix, is_query, sentence):
    alignment = {}
    while sentence:
        sentence, new_predicates = bracket(predicate_prefix, sentence, alignment)
        if sentence is None:
            return alignment
        if not is_query:
            new_alignments = define_premise_predicates(predicate_prefix, sentence, new_predicates)
        else:
            new_alignments = define_query_predicates(predicate_prefix, sentence, new_predicates)
        sentence = simplify(sentence, list(new_alignments.keys()))
        alignment.update(new_alignments)
    return alignment

###IF prompt
from typing import Dict, List, Tuple

@mock.proxymock(extract_premises_proxy)
def extract_premise_sentences(input_str: str) -> List[str]:
    """Extract the premise sentences from an input.

    The premises are the sentences that are assumed to be true in the
    question.  The premises do not include the hypothesis, which is
    the sentence making a statement which is asserted (correctly or
    incorrectly) to follow from the premises.
    """
    ...

@mock.proxymock(extract_hypothesis_proxy)
def extract_hypothesis_sentence(input_str: str) -> List[str]:
    """Extract the hypothesis sentence from an input.

    The hypothesis is the statement that is claimed (correctly or
    incorrectly) to follow from the premises.
    """
    ...

@mock.proxymock(bracket_proxy)
def bracket(predicate_prefix, sentence: str, alignments: Dict[str, Alignment]) -> Tuple[str, List[str]]:
    """
    Use step in an iterative parsing of the sentence.
    """
    ...

@mock.proxymock(define_predicates_proxy)
def define_premise_predicates(
        predicate_prefix, bracketed_sentence: str, new_predicates: List[str]) -> Dict[str, Alignment]:
    """Define each new predicate as a logical form.

    Return a mapping of predicate names to Alignments.
    """
    ...

@mock.proxymock(define_predicates_proxy)
def define_query_predicates(
        predicate_prefix, bracketed_sentence: str, new_predicates: List[str]) -> Dict[str, Alignment]:
    """Define each new predicate as a logical form.

    Return a mapping of predicate names to Alignments.
    """
    ...

@mock.proxymock(simplify_proxy)
def simplify(bracketed_sentence: str, new_alignments: Dict[str, Alignment]) -> str:
    """Remove the text version of the newly defined predicates from the bracketed string.
    """
    ...

@mock.proxymock(parse_premise_proxy)
def parse_premise(predicate_prefix:str, sentence: str) -> Dict[str, Alignment]:
    """Iteratively parse a sentence with a bottom-up algorithm.  While
    parsing, logic which captures the semantic meaning of the
    sentence.

    Predicates invented in the parse will be named using the
    predicate_prefix: e.g., if predicate_prefix is "p" then
    invented predicates will be named 'p1', 'p2', etc.
    """
    ...

@mock.proxymock(parse_query_proxy)
def parse_query(predicate_prefix:str, sentence: str) -> Dict[str, Alignment]:
    """Iteratively parse a sentence with a bottom-up algorithm.
    Generate logic which entails the atom query_true if and only if
    the query should succeed.

    Predicates invented in the parse will be named using the
    predicate_prefix: e.g., if predicate_prefix is "p" then
    invented predicates will be named 'p1', 'p2', etc.
    """
    ...

@mock.nullmock(sample_inputs=INPUTS)
def simple_parse(input_str):
    r"""
    Determine if formal reasoning supports hypothesis, given premised.

    ###DOCTESTS FOR simple_parse
    """
    ###IF toplevel ELSE ...
    premises = extract_premise_sentences(input_str)
    alignments = []
    for i, sentence in enumerate(premises):
        predstem = "pqrstuv"[i]
        alignments.append(parse_premise(predstem, sentence))
    text_hypothesis = extract_hypothesis_sentence(input_str)
    predstem = "pqrstuv"[len(premises)]
    h_alignment = parse_query(predstem, text_hypothesis)
    print(f'Final answer: parsed.')
    #for prem, al in zip(premises, alignments):
    #    asp(prem, al)
    #asp(text_hypothesis, h_alignment)
    ###ENDIF toplevel
###ENDIF prompt

if __name__ == '__main__':
    mock.main(locals())    

