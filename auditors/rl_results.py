import argparse
import json
from itertools import chain
import pandas as pd
import os
import re
from scipy.stats import fisher_exact
import sys

import audit
import auditors.util as util
import auditors.audit_medcalc as audit_medcalc
import log_util
import typicality

DEFAULT_METRIC = dict(
    aime24='ptp_math_pass@1:32_samples',
    math_500='ptp_extractive_match',
    gpqa_diamond='ptp_extractive_match',
    gsm8k='ptp_extractive_match',
    medcalc_bench_formulas='medcalc_bench_metric',
    medcalc_bench_rule='medcalc_bench_metric',    
    pubmedqa='pubmedqa_metric',
)

DEFAULT_AUDITOR_CLASS = dict(
    medcalc_bench_formulas=audit_medcalc.AuditMedcalcRLFormula,
    medcalc_bench_rules=audit_medcalc.AuditMedcalcRLRules,
)

HMM_SWEEP_RESULTS = dict(
    medqa=(1, 25),
    mmlu_pro_biology=(2, 50),
    mmlu_pro_health=(2, 50),
    pubmedqa=(2, 25),
    medcalc_bench_formulas=(2, 25),
    medcalc_bench_rules=(2, 50),
)

def load_data(args, stem):
    basedir = args.basedir
    filename = f'custom_{stem}_0_0.0_0_0_0.json'
    metric = args.metric or DEFAULT_METRIC.get(stem)

    data = util.load_json_details(
        os.path.join(basedir, 'details', filename))
    print(f'Loaded {len(data)} examples')
    results = util.load_json_correctness(
        os.path.join(basedir, 'results', filename),
        key2=metric)
    print('using cached result file')
    print(f'Loaded {len(results)} labels')
    for d, y in zip(data, results):
        d['is_correct'] = bool(y)
    return data

def collect_symbolic_audit_results(args, stem, data):

    auditor_class = DEFAULT_AUDITOR_CLASS.get(
        stem, audit.NullAuditor)
    print('auditor_class:', auditor_class)
    runner = audit.Runner(data, auditor_class, do_eval=True)
    runner.run()


    def fails(r, msg):
        return [a for a in r.audits if a['msg'] == msg and not a['passed']]

    rows = []
    all_audit_names = set(a['msg'] for r in runner.results for a in r.audits)
    for msg in all_audit_names:
        failing_results = [r for r in runner.results if fails(r, msg)]
        passing_results = [r for r in runner.results if not fails(r, msg)]
        def get_n_k(results):
            n = len(results)
            k = len([r for r in results if r.is_correct])
            return n, k
        n1, k1 = get_n_k(failing_results)
        n2, k2 = get_n_k(passing_results)
        if n1 == 0 or n2 == 0:
            continue
        acc1 = k1 / n1
        acc2 = k2 / n2
        diff = acc2 - acc1
        pvalue = fisher_exact([[n1, k1], [n2, k2]]).pvalue
        rows.append(dict(
            stem=stem, audit=msg, 
            k1=k1, n1=n1, acc1=acc1, 
            k2=k2, n2=n2, acc2=acc2, pvalue=pvalue))
    return rows
def collect_typicality_results(args, stem, data):

    #auditor_class = DEFAULT_AUDITOR_CLASS.get(
    #    stem, audit.NullAuditor)
    #print('auditor_class:', auditor_class)
    runner = audit.Runner(data, audit.NullAuditor, do_eval=True)
    runner.run()

    def stats(method, model_dfs):
        segment_df, diff_df = model_dfs
        acc1 = diff_df.acc1.iloc[0]
        acc2 = diff_df.acc2.iloc[0]
        diff = acc2 - acc1
        pvalue = diff_df.pvalue.iloc[0]
        return dict(
            stem=stem, method=method,
            acc1=acc1, acc2=acc2, diff=diff, pvalue=pvalue)

    all_stats = []
    print('\n ---- by errors ----')
    model = typicality.Errors(runner.results)
    errors_dfs = model.fit().postfit().report(num_splits=2)
    all_stats.append(stats('errors', errors_dfs))

    print('\n ---- by multinomial ----')
    model = typicality.Hmm(runner.results)
    multinomial_dfs = model.fit(n_components=1, ngram_size=0).postfit().report(num_splits=2)
    all_stats.append(stats('multinomial', multinomial_dfs))

    print('\n ---- by skeleton prob with old package ----')
    model = typicality.SkeletonLogProb(runner.results)
    skeleton_dfs = model.fit().postfit().report(num_splits=2)
    all_stats.append(stats('skeleton-old', skeleton_dfs))
    if args.skeleton_save_file:
        print(f'saving skeleton params to {args.skeleton_save_file}')
        with open(args.skeleton_save_file, 'w') as fp:
            json.dump(model.as_dict(), fp, indent=2)

    print('\n ---- by skeleton prob with hmms ----')
    model = typicality.Hmm(runner.results)
    skeleton_dfs = model.fit(n_components=1, ngram_size=9999).postfit().report(num_splits=2)
    all_stats.append(stats('skeleton', skeleton_dfs))

    print('\n ---- with hmms ----')
    model = typicality.Hmm(runner.results)
    # precomputed sweep parameters if available
    n_components, ngram_size = HMM_SWEEP_RESULTS.get(stem, (None, None))
    if n_components is not None:
        model.fit(n_components=n_components, ngram_size=ngram_size)
    else:
        model.sweep_and_fit(
            n_components_choices=(2, 5, 10),
            ngram_size_choices=(0, 3, 10, 25, 50))
    hmm_dfs = model.postfit().report(num_splits=2)
    all_stats.append(stats('hmm*', hmm_dfs))
    return all_stats


if __name__ == '__main__':
    parser = util.audit_argparser()
    parser.add_argument(
        '--basedir',
        default='/Users/wcohen/Documents/code/PTP_R1/evals/Qwen2.5-7B-Base-RL-Clean-V2/',
        help='dir to load from')
    parser.add_argument(
	'--stem',
	required=True,
        action='append',
	help='filestem, eg medcalc_bench_rules')
    parser.add_argument(
	'--skeleton_save_file',
	help='filename to save json version of skeleton params')
    parser.add_argument(
        '--metric',
        help='metric in cached_result'
    )
    parser.add_argument(
        '--symbolic',
        action='store_true',
        help='do symbolic (not typicality) audits'
    )

    args = parser.parse_args()
    if not args.stem:
        args.stem = ['gpqa_diamond', 'medqa', 'mmlu_pro_biology',
                     'mmlu_pro_health', 'pubmedqa']
    rows = []
    for stem in args.stem:
        data = load_data(args, stem)
        if args.symbolic:
            rows.extend(collect_symbolic_audit_results(args, stem, data))
        else:
            rows.extend(collect_typicality_results(args, stem, data))
    df = pd.DataFrame(rows)
    print()
    print(df)
